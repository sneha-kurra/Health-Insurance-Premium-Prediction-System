# -*- coding: utf-8 -*-
"""Copy of Medical_Cost_Insurance_pred (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Q8fXxrsblW-jUwPlIjIeef_kAu_bMRvg

<b>MEDICAL INSURANCE PREMIUM PREDICTION USING MACHINE LEARNING<B>

<B>PROBLEM DEFINITION<B>:The rising demand for healthcare and the increased cost of medical services globally make health insurance a crucial financial safeguard. The COVID-19 pandemic has further underscored the importance of accessible health insurance as protection against unforeseen health expenses. In the insurance industry, accurate and rapid prediction of individual health insurance premiums is essential for both companies and customers to assess potential costs and select suitable policies. This project aims to utilize machine learning techniques to predict individual health insurance costs.

<B>WHY THIS PROBLEM<B>:This problem addresses the need to accurately predict individual health insurance premiums using machine learning to help insurers with pricing and customers with planning for medical costs.

<B>MY APPROACH<B>:I used Linear Regression, Decision Tree, Random Forest models to predict health insurance premiums, leveraging each model's strengths—simplicity, interpretability, reduced overfitting, and local pattern recognition—to achieve accurate predictions.
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import matplotlib.pyplot as plt
import seaborn as sns

data = pd.read_csv('/content/medical_insurance.csv')
data.head()

data.shape

data.info()

"""### **PRE-PROCESSING DATA**"""

data.isnull().sum()

"""**There are missing values or null values in bmi,children and charges**"""

# Mean imputation for BMI and charges
data['bmi'] = data['bmi'].fillna(data['bmi'].mean())
data['charges'] = data['charges'].fillna(data['charges'].mean())

# Mode imputation for children
data['children'] = data['children'].fillna(data['children'].mode()[0])

# Show the dataframe after imputations
print(data)

"""<b>After Data Imputation<b>

"""

data.isnull().sum()

data['region'].value_counts().sort_values()

data['children'].value_counts().sort_values()

data.describe()

"""### Converting Categorical Features to Numerical using One hot Encoding"""

#get_dummies to strings, sex, smoker and region and concat with original data
data_dummied = pd.concat([data, pd.get_dummies(data[['sex', 'smoker', 'region']])], axis=1)

#drop the columns that i get_dummied
data_dummied.drop(columns=['sex', 'smoker', 'region'], inplace=True)

data_dummied.head()

"""# **EDA (EXPLORATORY DATA ANALYSIS)**"""

print(data['sex'].value_counts().sort_values())
print(data['smoker'].value_counts().sort_values())
print(data['region'].value_counts().sort_values())

plt.figure(figsize=(12,9))
plt.title('Age vs Charge')
sns.barplot(x='age',y='charges',data=data,palette='husl')

plt.figure(figsize=(10,7))
plt.title('Region vs Charge')
sns.barplot(x='region',y='charges',data=data,palette='Set3')

plt.figure(figsize=(7,5))
sns.scatterplot(x='bmi',y='charges',hue='sex',data=data,palette='Reds')
plt.title('BMI VS Charge')

plt.figure(figsize=(10,7))
plt.title('Smoker vs Charge')
sns.barplot(x='smoker',y='charges',data=data,palette='Blues',hue='sex')

plt.figure(figsize=(10,7))
plt.title('Sex vs Charges')
sns.barplot(x='sex',y='charges',data=data,palette='Set1')

#heatmap
plt.figure(figsize=(12,9))
sns.heatmap(data_dummied.corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.show()

"""### There might be few outliers in Charges but then we cannot say that the value is an outlier as there might be cases in which Charge for medical was very les actually!

### Based on the above plots we scaled BMI Column using MinMax scaler
"""

from sklearn.preprocessing import MinMaxScaler
data_pre = data_dummied.copy()
scaler = MinMaxScaler()
data_pre['bmi'] = scaler.fit_transform(data_pre[['bmi']])
data_pre.head()

final_df = data_pre.copy()

final_df.head()

final_df.shape

# Data Splitting
from sklearn.model_selection import train_test_split

# Preprocessing
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer

# Regression Models
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor

# Evaluation Metrics
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

X = final_df.drop(columns=['charges'], axis=1)
y = final_df['charges']

#Train Test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)

print('Size of X_train : ', X_train.shape)
print('Size of y_train : ', y_train.shape)
print('Size of X_test : ', X_test.shape)
print('Size of Y_test : ', y_test.shape)

"""## **Modelling**


*   Linear Regression
*   Decision Tree
*   Random Forest
*   K-Nearest Neighbors (KNN)







"""

# Models
lr = LinearRegression()
dtr = DecisionTreeRegressor()
rfr = RandomForestRegressor(n_estimators=2)
knn = KNeighborsRegressor()

#Training models
lr.fit(X_train, y_train)
dtr.fit(X_train, y_train)
rfr.fit(X_train, y_train)
knn.fit(X_train,y_train)

lr_pred = lr.predict(X_test)
dtr_pred = dtr.predict(X_test)
rfr_pred = rfr.predict(X_test)
knn_pred = knn.predict(X_test)

#Dictionary
models = {
    'Linear Regression': lr_pred,
    'Decision Tree Regression': dtr_pred,
    'Random Forest Regression': rfr_pred,
    'KNeighbors regressor': knn_pred,
}

#Models performance
for model_name, predictions in models.items():
    r2_score_model = r2_score(y_test, predictions)
    mse_score = mean_squared_error(y_test, predictions)
    mae_score = mean_absolute_error(y_test, predictions)

    print("Model:", model_name)
    print("R2 Score:", r2_score_model)
    print("MSE Score:", mse_score)
    print("MAE Score:", mae_score)
    print()

"""<b>Decision Tree Regressor and Random Forest Regressor are the top-performing models, with high R² scores and low error metrics.<b>

<b>Prediction<b>
"""

def predict_charges(age, sex, bmi, children, smoker, region):
    # Convert input features to the engineered format
    features = {
        'age': [age],
        'bmi': [bmi],
        'children': [children],
        'sex_female': [1 if sex == 'female' else 0],
        'sex_male': [1 if sex == 'male' else 0],
        'smoker_no': [1 if smoker == 'no' else 0],
        'smoker_yes': [1 if smoker == 'yes' else 0],
        'region_northeast': [1 if region == 'northeast' else 0],
        'region_northwest': [1 if region == 'northwest' else 0],
        'region_southeast': [1 if region == 'southeast' else 0],
        'region_southwest': [1 if region == 'southwest' else 0]
    }
    # Convert to DataFrame
    input_data = pd.DataFrame(features)
    input_data['bmi'] = scaler.transform(input_data[['bmi']])

    # Load the model and make a prediction
    prediction = dtr.predict(input_data)

    return prediction[0]

# Step 3: Get user input for real-time prediction
age = int(input("Enter age: "))
sex = input("Enter sex (male/female): ").lower()
bmi = float(input("Enter BMI: "))
children = int(input("Enter number of children: "))
smoker = input("Are you a smoker? (yes/no): ").lower()
region = input("Enter region (northeast/northwest/southeast/southwest): ").lower()
# Predict charges
predicted_charges = predict_charges(age, sex, bmi, children, smoker, region)
print(f"Predicted Insurance Charges: Rs.{predicted_charges:.2f}")

"""<B>CONCLUSION<B>:The Decision Tree model, with its high R² score, outperformed other models in accurately predicting health insurance premiums based on user inputs, making it the most effective choice for this task."""